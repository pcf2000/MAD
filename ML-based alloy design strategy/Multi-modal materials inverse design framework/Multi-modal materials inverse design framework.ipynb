{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9173b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_excel('UTS.xlsx')\n",
    "\n",
    "# 分割数据\n",
    "X = data.iloc[:, 1:]\n",
    "Y = data.iloc[:, 0]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=73)\n",
    "\n",
    "# 最佳参数\n",
    "best_params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 5.411729501146951,\n",
    "    'n_estimators': 139,\n",
    "    'reg_alpha': 1.0,\n",
    "    'reg_lambda': 1.0,\n",
    "    'subsample': 0.5,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "UTS_model = xgb.XGBRegressor(**best_params)\n",
    "UTS_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_excel('EL.xlsx')\n",
    "\n",
    "# 分割数据\n",
    "X = data.iloc[:, 1:]\n",
    "Y = data.iloc[:, 0]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=16)\n",
    "\n",
    "# 最佳参数\n",
    "best_params = {\n",
    "    'bootstrap': False,\n",
    "    'max_depth': 10,\n",
    "    'max_features': 0.5,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 5,\n",
    "    'n_estimators': 55\n",
    "}\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "EL_model = RandomForestRegressor(**best_params, random_state=25)\n",
    "EL_model.fit(x_train, y_train)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_excel('HV.xlsx')\n",
    "\n",
    "# 分割数据\n",
    "X = data.iloc[:, 1:]\n",
    "Y = data.iloc[:, 0]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=75)\n",
    "\n",
    "# 最佳参数\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.7537221430165258,\n",
    "    'learning_rate': 0.07141712725507017,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1.036994365622379,\n",
    "    'n_estimators': 179,\n",
    "    'reg_alpha': 0.07844930740270828,\n",
    "    'reg_lambda': 0.4659923785137676,\n",
    "    'subsample': 0.5124079817369307,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "Hardness_model = xgb.XGBRegressor(**best_params)\n",
    "Hardness_model.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#\n",
    "\n",
    "# 目标值\n",
    "target_UTS = 300  # 设定目标UTS值\n",
    "target_EL = 3.5    # 设定目标EL值\n",
    "target_Hardness = 120  # 设定目标Hardness值\n",
    "\n",
    "# 权重\n",
    "weight_UTS = 1  # UTS的权重\n",
    "weight_EL = 1   # EL的权重\n",
    "weight_Hardness = 1  # Hardness的权重\n",
    "\n",
    "# 定义目标函数\n",
    "def target_function(**params):\n",
    "    params_df = pd.DataFrame([params], columns=X.columns)  # 保证特征顺序一致\n",
    "    pred_UTS = UTS_model.predict(params_df)[0]\n",
    "    pred_EL = EL_model.predict(params_df)[0]\n",
    "    pred_Hardness = Hardness_model.predict(params_df)[0]\n",
    "    \n",
    "    # 计算目标值：三个预测性能与目标性能的比值之和\n",
    "    ratio_UTS = pred_UTS / target_UTS\n",
    "    ratio_EL = pred_EL / target_EL\n",
    "    ratio_Hardness = pred_Hardness / target_Hardness\n",
    "    \n",
    "    score =weight_UTS*abs(ratio_UTS - 1) + weight_EL*abs(ratio_EL - 1) + weight_Hardness*abs(ratio_Hardness - 1)\n",
    "    \n",
    "    return -score  # 优化器会最大化目标函数，所以这里返回负值以最小化差值\n",
    "\n",
    "# 定义特征的容许范围\n",
    "pbounds = {\n",
    "    'Al': (3.0, 8.0),  # 例如铝的范围从0到10\n",
    "    'Cu': (0.0, 6.0),   # 例如铜的范围从0到5\n",
    "    'Mg': (0.0, 0.05),   # 例如镁的范围从0到5\n",
    "    'Ti': (0.0, 0.0),   # 例如钛的范围从0到5\n",
    "    'Mn': (0.0, 0.0),   # 例如锰的范围从0到5\n",
    "    'Si': (0.0, 0.0),   # 例如硅的范围从0到5\n",
    "    'La': (0.0, 0.0),   # 例如镧的范围从0到5\n",
    "    'Ce': (0.0, 0.0)    # 例如铈的范围从0到5\n",
    "}\n",
    "\n",
    "# 贝叶斯优化\n",
    "optimizer = BayesianOptimization(\n",
    "    f=target_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# 最大迭代次数\n",
    "n_iter = 50\n",
    "\n",
    "# 运行贝叶斯优化\n",
    "optimizer.maximize(init_points=10, n_iter=n_iter)\n",
    "\n",
    "# 获取最佳参数\n",
    "best_params = optimizer.max['params']\n",
    "best_params_df = pd.DataFrame([best_params], columns=X.columns)  # 保证特征顺序一致\n",
    "best_pred_UTS = UTS_model.predict(best_params_df)[0]\n",
    "best_pred_EL = EL_model.predict(best_params_df)[0]\n",
    "best_pred_Hardness = Hardness_model.predict(best_params_df)[0]\n",
    "\n",
    "# 容忍误差\n",
    "tolerance_UTS = 20  # 可以根据需要调整\n",
    "tolerance_EL = 0.5  # 可以根据需要调整\n",
    "tolerance_Hardness = 10 # 可以根据需要调整\n",
    "\n",
    "# 检查是否在容忍误差范围内\n",
    "if (abs(best_pred_UTS - target_UTS) <= tolerance_UTS and\n",
    "    abs(best_pred_EL - target_EL) <= tolerance_EL and\n",
    "    abs(best_pred_Hardness - target_Hardness) <= tolerance_Hardness):\n",
    "    print(f\"找到的最佳参数: {best_params}\")\n",
    "    print(f\"预测的UTS值: {best_pred_UTS}\")\n",
    "    print(f\"预测的EL值: {best_pred_EL}\")\n",
    "    print(f\"预测的Hardness值: {best_pred_Hardness}\")\n",
    "else:\n",
    "    print(\"在指定迭代次数内未找到满足条件的解。\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
